# Projeto de ClassificaÃ§Ã£o de Campanha de Marketing

Este projeto tem como objetivo aplicar tÃ©cnicas de **Machine Learning supervisionado** para prever o sucesso de campanhas de marketing, utilizando um conjunto de dados **fictÃ­cio**. Foi conduzido todo o fluxo de um projeto de ciÃªncia de dados, desde a exploraÃ§Ã£o dos dados atÃ© a explicaÃ§Ã£o dos modelos com SHAP.

---

## Objetivo

Construir um modelo preditivo capaz de classificar corretamente se uma campanha serÃ¡ **bem-sucedida (1)** ou **mal-sucedida (0)**, com base em dados comportamentais e financeiros dos clientes.

---

## Estrutura do Projeto

```bash
marketing-project/
â”‚
â”œâ”€â”€ data/ # Dados brutos e limpos
â”‚ â””â”€â”€ df_temp.csv
â”‚
â”œâ”€â”€ notebooks/ # Notebooks do projeto
â”‚ â”œâ”€â”€ 01_EDA.ipynb
â”‚ â”œâ”€â”€ 02_Modelagem_XGBoost.ipynb
â”‚ â”œâ”€â”€ 03_Validacao_Cruzada.ipynb
â”‚ â””â”€â”€ 04_SHAP_Explicabilidade.ipynb
â”‚
â”œâ”€â”€ images/ # GrÃ¡ficos salvos
â”‚ â”œâ”€â”€ confusion_matrix.png
â”‚ â”œâ”€â”€ roc_curve.png
â”‚ â””â”€â”€ shap_summary.png
â”‚
â”œâ”€â”€ requirements.txt # DependÃªncias do projeto
â””â”€â”€ README.md # Este arquivo
```

---

## ğŸ” Etapas Realizadas

### 1. PrÃ©-processamento
- ExclusÃ£o e imputaÃ§Ã£o de dados faltantes
- CodificaÃ§Ã£o de variÃ¡veis categÃ³ricas
- ExtraÃ§Ã£o de partes de datas
- NormalizaÃ§Ã£o de colunas numÃ©ricas, se necessÃ¡rio

### 2. AnÃ¡lise ExploratÃ³ria (EDA)
- AvaliaÃ§Ã£o da distribuiÃ§Ã£o das variÃ¡veis
- AnÃ¡lise bivariada entre `sucesso` e variÃ¡veis preditoras
- VerificaÃ§Ã£o de outliers e colinearidade

### 3. Modelagem com XGBoost
- SeparaÃ§Ã£o treino/teste com `train_test_split`
- AvaliaÃ§Ã£o com `classification_report` e matriz de confusÃ£o
- **ValidaÃ§Ã£o cruzada estratificada (k=5)** com `StratifiedKFold`
- CÃ¡lculo de mÃ©tricas globais como F1 Macro

### 4. InterpretaÃ§Ã£o do Modelo
- AnÃ¡lise de `feature_importances_` do XGBoost
- InterpretaÃ§Ã£o com `SHAP` (importÃ¢ncia global e impacto individual)

---

## ğŸ“ˆ Resultados

### ğŸ“Œ ValidaÃ§Ã£o Cruzada (F1 Macro)

```text
F1 macro por fold: [0.5417, 0.5139, 0.6827, 0.5249, 0.4327]
MÃ©dia do F1 macro: 0.5392
ğŸ“‰ Curva ROC

AUC = 0.54

Modelo tem desempenho prÃ³ximo ao aleatÃ³rio, sinalizando que ajustes sÃ£o necessÃ¡rios

ğŸ§¾ Matriz de ConfusÃ£o (exemplo)

ğŸ’¡ Principais Insights
O modelo tem dificuldade em generalizar, possivelmente por:

Baixo nÃºmero de amostras (150 linhas)

Alta dimensionalidade (283 colunas)

PossÃ­vel desbalanceamento das classes

A classe 1 (sucesso) Ã© melhor reconhecida que a classe 0

AUC e F1 abaixo de 0.60 sugerem desempenho insuficiente para uso real

ğŸ”§ Tecnologias Utilizadas
Python 3.10+

pandas, numpy, matplotlib, seaborn

scikit-learn

XGBoost

SHAP

Jupyter Notebook

âš ï¸ ObservaÃ§Ãµes
Os dados utilizados sÃ£o fictÃ­cios e nÃ£o representam clientes reais.

Este projeto tem fins educacionais e demonstrativos.

ğŸš€ PrÃ³ximos Passos
ğŸ” Aplicar reduÃ§Ã£o de dimensionalidade (SelectKBest, PCA)

âš–ï¸ Balanceamento de classes com SMOTE

ğŸ”„ Testar outros algoritmos (RandomForest, LightGBM, LogisticRegression)

ğŸ“Š Realizar tuning com GridSearchCV

ğŸ“ˆ Avaliar performance em novos conjuntos de dados simulados
